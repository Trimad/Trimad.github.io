<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Hugo Grimoire</title>
    <link>http://localhost:1313/categories/python/</link>
    <description>Recent content in Python on Hugo Grimoire</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Mon, 25 Mar 2024 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/categories/python/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Window Watcher</title>
      <link>http://localhost:1313/post/2024-03-25-window-watcher/</link>
      <pubDate>Mon, 25 Mar 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2024-03-25-window-watcher/</guid>
      <description>
        
          
            Use a machine vision model to watch a window.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Local AI API</title>
      <link>http://localhost:1313/post/2024-02-05-local-ai-api/</link>
      <pubDate>Mon, 05 Feb 2024 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2024-02-05-local-ai-api/</guid>
      <description>
        
          
            Short scripts for image-to-text, text-to-sound, etc.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Generate Knowledge Graphs with LLMs</title>
      <link>http://localhost:1313/post/2023-12-14-pyvis-knowledge-graphs/</link>
      <pubDate>Thu, 14 Dec 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2023-12-14-pyvis-knowledge-graphs/</guid>
      <description>
        
          
            This is a work in progress exploration of generating knowledge graphs with LLMs, inspired by a post I read on towardsdatascience.com.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Python networkx Library</title>
      <link>http://localhost:1313/post/2023-08-15-networkx/</link>
      <pubDate>Mon, 14 Aug 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2023-08-15-networkx/</guid>
      <description>
        
          
            A Python script for visualizing nodes with the networkx library.
          
          
        
      </description>
    </item>
    
    <item>
      <title>QR Codes</title>
      <link>http://localhost:1313/post/2023-06-24-qr/</link>
      <pubDate>Sat, 24 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2023-06-24-qr/</guid>
      <description>
        
          
            Python script for generating a QR code.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Deforum Cheat Sheet</title>
      <link>http://localhost:1313/post/2023-05-24-deforum-cheat-sheet/</link>
      <pubDate>Wed, 24 May 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2023-05-24-deforum-cheat-sheet/</guid>
      <description>
        
          
            This is a cheat sheet of animations showing what the various 3D translation and rotation settings do in Deforum Stable Diffusion.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Deep Floyd IF</title>
      <link>http://localhost:1313/post/2023-05-03-deep-floyd-if/</link>
      <pubDate>Wed, 03 May 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2023-05-03-deep-floyd-if/</guid>
      <description>
        
          
            My tentative work flow for running Deep Floyd IF locally for image generation.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Thin Plate Spline Motion Model</title>
      <link>http://localhost:1313/post/2023-04-12-thin-plate-spline-motion-model/</link>
      <pubDate>Wed, 12 Apr 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2023-04-12-thin-plate-spline-motion-model/</guid>
      <description>
        
          
            This is my tentative workflow for using this repository to animate static images using a driving video.
          
          
        
      </description>
    </item>
    
    <item>
      <title>OpenAI Whisper</title>
      <link>http://localhost:1313/post/2023-02-24-openai-whisper/</link>
      <pubDate>Fri, 24 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2023-02-24-openai-whisper/</guid>
      <description>
        
          
            Whisper is a general-purpose speech recognition model. It is trained on a large dataset of diverse audio and is also a multi-task model that can perform multilingual speech recognition as well as speech translation and language identification.
          
          
        
      </description>
    </item>
    
    <item>
      <title>Decode Phishing Emails</title>
      <link>http://localhost:1313/post/2023-02-15-decode-phishing-emails/</link>
      <pubDate>Wed, 15 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2023-02-15-decode-phishing-emails/</guid>
      <description>
        
          
            I&#39;ve notice that a lot of phishing emails use hexadecimal strings to obfuscate their JavaScript. These are some Python scripts useful for identifying where form actions are POSTing to.
          
          
        
      </description>
    </item>
    
    <item>
      <title>MiDaS</title>
      <link>http://localhost:1313/post/2023-02-06-midas/</link>
      <pubDate>Mon, 06 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2023-02-06-midas/</guid>
      <description>
        
          
            GitHub RepositoryDuring installation, I ran into an issue where the CUDA package wasn&#39;t found. Had to modify environment.yaml to:
1name: midas-py310 2channels: 3 - pytorch 4 - defaults 5dependencies: 6 - nvidia::cuda-toolkit=11.7.0 7 - python=3.10.8 8 - pytorch::pytorch=1.13.0 9 - torchvision=0.14.0 10 - pip=22.3.1 11 - numpy=1.23.4 12 - pip: 13 - opencv-python==4.6.0.66 14 - imutils==0.5.4 15 - timm==0.6.12 16 - einops==0.6.0 Commands that were helpful for troubleshooting CUDA:
          
          
        
      </description>
    </item>
    
    <item>
      <title>Frame Interpolation Large Motion (FILM)</title>
      <link>http://localhost:1313/post/2023-02-05-film/</link>
      <pubDate>Sun, 05 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2023-02-05-film/</guid>
      <description>
        
          
            *&#34;The official Tensorflow 2 implementation of our high quality frame interpolation neural network. We present a unified single-network approach that doesn&#39;t use additional pre-trained networks, like optical flow or depth, and yet achieve state-of-the-art results. We use a multi-scale feature extractor that shares the same convolution weights across the scales. Our model is trainable from frame triplets alone.&#34;*
          
          
        
      </description>
    </item>
    
    <item>
      <title>Stable Diffusion Scripts</title>
      <link>http://localhost:1313/post/2023-02-05-stable-diffusion/</link>
      <pubDate>Sun, 05 Feb 2023 00:00:00 +0000</pubDate>
      
      <guid>http://localhost:1313/post/2023-02-05-stable-diffusion/</guid>
      <description>
        
          
            Stable Diffusion is an image generation technique that uses a diffusion process to iteratively generate images. It starts with a noise image and applies a series of transformations to it, where each transformation adds a little bit of noise to the image. These transformations are repeated over multiple time steps, and the amount of noise added is gradually decreased over time. This process smooths out the noise and generates a high-quality image. The stability of the diffusion process is maintained by scaling the added noise based on the image&#39;s current state, preventing the image from diverging or collapsing into a uniform color. Stable Diffusion is a powerful and versatile image generation technique that can produce realistic, high-resolution images with fine details and a wide range of styles.
          
          
        
      </description>
    </item>
    
  </channel>
</rss>
