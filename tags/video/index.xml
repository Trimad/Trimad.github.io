<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>video on Hugo Grimoire</title><link>https://trimad.github.io/tags/video/</link><description>Recent content in video on Hugo Grimoire</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Sat, 24 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://trimad.github.io/tags/video/index.xml" rel="self" type="application/rss+xml"/><item><title>QR Codes</title><link>https://trimad.github.io/post/2023-06-24-qr/</link><pubDate>Sat, 24 Jun 2023 00:00:00 +0000</pubDate><guid>https://trimad.github.io/post/2023-06-24-qr/</guid><description>
Decorative QR code ideas. Generated with Stable Diffusion.</description></item><item><title>Deforum Cheat Sheet</title><link>https://trimad.github.io/post/2023-05-24-deforum-cheat-sheet/</link><pubDate>Wed, 24 May 2023 00:00:00 +0000</pubDate><guid>https://trimad.github.io/post/2023-05-24-deforum-cheat-sheet/</guid><description>
This is a cheat sheet of animations showing what the various 3D translation and rotation settings do in Deforum Stable Diffusion.</description></item><item><title>Thin Plate Spline Motion Model</title><link>https://trimad.github.io/post/2023-04-12-thin-plate-spline-motion-model/</link><pubDate>Wed, 12 Apr 2023 00:00:00 +0000</pubDate><guid>https://trimad.github.io/post/2023-04-12-thin-plate-spline-motion-model/</guid><description>
This is my tentative workflow for using this repository to animate static images using a driving video.</description></item><item><title>MiDaS</title><link>https://trimad.github.io/post/2023-02-06-midas/</link><pubDate>Mon, 06 Feb 2023 00:00:00 +0000</pubDate><guid>https://trimad.github.io/post/2023-02-06-midas/</guid><description>
GitHub Repository During installation, I ran into an issue where the CUDA package wasn't found. Had to modify environment.yaml to:
1name: midas-py310 2channels: 3 - pytorch 4 - defaults 5dependencies: 6 - nvidia::cuda-toolkit=11.7.0 7 - python=3.10.8 8 - pytorch::pytorch=1.13.0 9 - torchvision=0.14.0 10 - pip=22.3.1 11 - numpy=1.23.4 12 - pip: 13 - opencv-python==4.6.0.66 14 - imutils==0.5.4 15 - timm==0.6.12 16 - einops==0.6.0 Commands that were helpful for troubleshooting CUDA:</description></item><item><title>Frame Interpolation Large Motion (FILM)</title><link>https://trimad.github.io/post/2023-02-05-film/</link><pubDate>Sun, 05 Feb 2023 00:00:00 +0000</pubDate><guid>https://trimad.github.io/post/2023-02-05-film/</guid><description>
*"The official Tensorflow 2 implementation of our high quality frame interpolation neural network. We present a unified single-network approach that doesn't use additional pre-trained networks, like optical flow or depth, and yet achieve state-of-the-art results. We use a multi-scale feature extractor that shares the same convolution weights across the scales. Our model is trainable from frame triplets alone."*</description></item><item><title>Stable Diffusion Scripts</title><link>https://trimad.github.io/post/2023-02-05-stable-diffusion/</link><pubDate>Sun, 05 Feb 2023 00:00:00 +0000</pubDate><guid>https://trimad.github.io/post/2023-02-05-stable-diffusion/</guid><description>
Stable Diffusion is an image generation technique that uses a diffusion process to iteratively generate images. It starts with a noise image and applies a series of transformations to it, where each transformation adds a little bit of noise to the image. These transformations are repeated over multiple time steps, and the amount of noise added is gradually decreased over time. This process smooths out the noise and generates a high-quality image. The stability of the diffusion process is maintained by scaling the added noise based on the image's current state, preventing the image from diverging or collapsing into a uniform color. Stable Diffusion is a powerful and versatile image generation technique that can produce realistic, high-resolution images with fine details and a wide range of styles.</description></item><item><title>ffmpeg</title><link>https://trimad.github.io/post/2022-01-27-ffmpeg/</link><pubDate>Thu, 27 Jan 2022 00:00:00 +0000</pubDate><guid>https://trimad.github.io/post/2022-01-27-ffmpeg/</guid><description>
ffmpeg is a complete, cross-platform solution to record, convert and stream audio and video.
ffmpeg Download ffmpeg Documentation Audio Processing Convert to 8kHz, single-channel PCM 1ffmpeg -i &amp;#34;input.mp3&amp;#34; -ar 8000 -ac 1 output.wav Convert to 16kHz, single-channel PCM 1ffmpeg -i &amp;#34;input.mp3&amp;#34; -ar 16000 -ac 1 output.wav Convert to 48kHz, single-channel PCM 1ffmpeg -i input.mp3 -ar 48000 -ac 1 output.wav Video Processing Add Music to a Video 1ffmpeg -i video.mp4 -i music.</description></item></channel></rss>